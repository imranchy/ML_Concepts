# -*- coding: utf-8 -*-
"""Imran_ML_Concepts_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12m5pl6S3GFiyPrbydnR3WRIReWigMx1W

#Introduction
In this project, I have worked with the Car Sales Adverts Dataset provided by AutoTrader (AT), which contains several vehicle adverts dataset that contains information of various features of them such as age, colour makes, selling price and so on.

This project aims to build and train both the regression and classification models on the given dataset. To reach this aim I have structured the tasks into two parts, the first I called the Regression part and the second the Classification Part. For the completion of both these parts I have first read the data, then I have explored the data to identify the possible important features and fix the errors in the data.  I have prepared the cleaned data for building and training the ML Models in the next step. After training the models and getting the results, I used some evaluation metrics for the Regression and Classification tasks to assess model performances. The main findings from this project are that from the Regression part I found Lasso regression to perform slightly better than other models whereas for the Classification task the KNN had the higher accuracy among other classification models used in this project.
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing important Libraries
# %config InlineBackend.figure_formats = set(('retina', 'svg'))
import pandas as pdith 
import seaborn as sns
from scipy import stats
sns.set(style='ticks', font_scale=0.8)

from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error
)

from functools import partial
root_mean_squared_error = partial(mean_squared_error, squared=True)
from sklearn.model_selection import cross_val_score

from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import balanced_accuracy_score, accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.pipeline import make_pipeline, Pipeline

"""###Data Loading for the Regression Part"""

#Data Loading
from google.colab import drive
drive.mount('/content/drive')

Path = 'drive/My Drive/MLConceptsAssignment'

# read CSV file from the 'data' subdirectory using a relative path
reg_df = pd.read_csv(Path+'/Adverts_Regression.csv')
reg_df.head()

"""###Data Exploration"""

reg_df.info()

reg_df.describe()

# Further data analysis to drop some features
reg_df['crossover_car_and_van'].value_counts()

reg_df['vehicle_condition'].value_counts()

reg_df = reg_df.drop(columns=['reg_code','vehicle_condition','crossover_car_and_van'])
reg_df.head()

from sklearn.preprocessing import LabelEncoder

lab_df = reg_df.apply(LabelEncoder().fit_transform)

plt.figure(figsize=(12,10))
cor = lab_df.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

corr_Price=cor["price"].sort_values(ascending=False)
print(corr_Price)

reg_df = reg_df.drop(columns=['public_reference','standard_colour','year_of_registration','standard_make','standard_model'])
reg_df.head()

"""The dataset contains a total of 14 columns. For the Regression task, the 'price' column is the value we will predict leaving the rest as predictor variables. By loading the data I found some missing values in the 'reg_code' and 'mileage' columns and the presence of outliers in the dataset by getting the description of the data. Initially, I have decided to drop the 'reg_code' which are the registration codes of the cars we are dealing with. My intuition is that these values generally cannot have any influence on car prices. But they could be analysed further for future work.

After looking at the value counts of the 'crossover_car_and_van' and 'vehicle_condition' columns we can see that they only have one type of value so the Machine Learning models will not be able to learn anything from these features so I have decided to drop them as well along with 'reg_code' from the dataset.

To understand some correlation between the rest of the features and the price variable I have drawn a correlation matrix of the features which show  Pearsonâ€™s correlation coefficients among the features. As we have some categorical features in our data so I have used the LabelEncoder class to encode the categorical variables to 0s and 1s. By using the pandas inbuilt corr() method and matplotlib I have drawn the correlation plot among the features. From the plot we can see that 'public_reference' and 'standard_colour' have low correlations between 'price', the registration years have a value of 0.74 whereas the value of age is -0.74. After carefully looking at the 'year_of_registration' and the 'age' columns I found out the ages have been calculated by deducting the current year (2022) from the values to get the ages. Finally, I have decided to drop 'standard_make' and 'standard_model' because we also have the 'make_model' feature which is the combination of 'standard_make' and 'standard_model'.

###Data Fixing
"""

#Dealing with outliers
Q1 = reg_df.quantile(0.25)
Q3 = reg_df.quantile(0.75)
IQR = Q3 - Q1

reg_df = reg_df[~((reg_df < (Q1 - 1.5 * IQR)) |(reg_df > (Q3 + 1.5 * IQR))).any(axis=1)]
reg_df.shape

# Dealing Missing values
reg_df.isnull().sum()

reg_df['mileage'] = reg_df['mileage'].fillna(reg_df['mileage'].median())
reg_df.isnull().sum()

"""To deal with the outliers in the continuous variables I calculated the Inter Quartile Range of those features and kept the data within that range. Then I found some missing values in the mileage column and to deal with them I replaced them with mileage columns median value rather than mean value as the median value will give a better representation of the majority of values in the mileage column whereas dropping them completely would make the trained models (in case of both regression and classification models) lose some data understanding which would result in a negative impact on the model performances. 

https://medium.com/analytics-vidhya/feature-engineering-part-1-mean-median-imputation-761043b95379#:~:text=Therefore%2C%20replacing%20missing%20values%20by,common%20practice%20for%20numerical%20variables.&text=Therefore%2C%20the%20median%20is%20a,the%20values%20in%20the%20variable.

###Data Preparation for Regression Models
"""

# Separating the dependent variables (X) and Target variable (y) from the dataset
X = reg_df.drop(columns='price')
y = reg_df['price']
X.head()

y

#Getting the dummy variables and dropping the extra columns to avoid multi colinearity
X = pd.get_dummies(data=reg_df, drop_first=True)
X.head()

#Spliting the data into training and testing sets
from sklearn.model_selection  import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train.shape, X_test.shape

#Standardising the data
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)
X_scaled = scaler.fit_transform(X)
X_scaled

"""For any kind of Machine Learning tasks, we generally see the use of 20% data to be set as the test size leaving the rest as training size and I have also done the same. By doing so the models will have enough training data to learn from and I will follow the same method for the Classification part of this task.

Scaling is an important part of Machine Learning projects as unscaled data may lead to the models misinterpreting the training data resulting in poor model performance. For this project, I have used Standard Scaler which transforms the Dataset into each features Z-Scores. Throughout Machine Learning literature we find that this scaler is used often and it provides better results compared to other scalers. After running the MinMax Scaler in the rough work I have also found out that the models run after the Scaling with StandardScaler yield better results and I will use the same scaler for running the Classification part of this project.

To predict the prices of vehicles I have used several regression models. To evaluate them I have used the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) of the models. The MSE is one of the most commonly used performance evaluation metrics for regression models which finds the sum of the squared difference between the actual and the predicted values of the prices divided by the number of observations in the dataset and RMSE is the Square Root of the MSE. The outputs of the RMSE are easier to interpret as they are of the same unit as the output variable.

https://www.analyticsvidhya.com/blog/2021/05/know-the-best-evaluation-metrics-for-your-regression-model/

Relying only on the RMSE Score on the Test Set does not give us the full measure of a models performance, so to validate the results I have calculated a number of RMSE Scores by using the K Fold Cross Validation which is a process in which one sample of a dataset is held as a test set and the rest as training set where the model is run those sets of data and this is done K number of times where K is input by the engineers. This process is better than train_test_split because it makes sure that the model is trained and tested on all of the data.

https://medium.com/@mtterribile/understanding-cross-validations-purpose-53490faf6a86

I ran K Fold Cross Validation by setting K 10 times as this is commonly done in Machine Learning projects. I have also used the Repeated K Fold Cross-validation to validate the models further a total of 40 times. I then finally calculated the residuals and plotted the true values against the predictions made by the models.

#Building, Training and Evaluation of the Regression Models

###Multi Linear Regression Model
"""

# Fitting Multiple Linear Regression to the Training set
from sklearn import linear_model
lr = linear_model.LinearRegression()
lr.fit(X_train_scaled, y_train)

#Making the predictions on the test set
y_pred_lr = lr.predict(X_test_scaled)
y_pred_lr

#Evaluating the model
print("RMSE of the Multi Linear Regression Model is: ",root_mean_squared_error(y_test, y_pred_lr))

#Cross validation of the model
RMSEs = cross_val_score(lr, X_scaled, y, scoring='neg_root_mean_squared_error', cv=10)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

from sklearn.model_selection import RepeatedKFold
cv_strategy=RepeatedKFold(
    n_splits=5, n_repeats=8, random_state=0
)
RMSEs = cross_val_score(lr, X_scaled, y, scoring='neg_root_mean_squared_error', cv=cv_strategy)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

residuals_lr = lr.predict(X_scaled) - y
residuals_lr.head()

sns.histplot(x=residuals_lr, kde=True, stat='proportion');

residuals_lr.mean(), residuals_lr.median(), residuals_lr.std()

g = sns.jointplot(x=y, y=lr.predict(X_scaled), alpha=0.5)
x0, x1 = g.ax_joint.get_xlim()
y0, y1 = g.ax_joint.get_ylim()
lims = [min(x0, y0), max(x1, y1)] 
lims = [0, max(x1, y1)]
g.ax_joint.set(xlim=lims, ylim=lims)
g.ax_joint.plot(lims, lims, ':k', alpha=0.3, lw=1);
g.ax_joint.set(xlabel='True Target Value')
g.ax_joint.set(ylabel='Predicted Target Value');

"""###Decision Tree Regressor"""

# import the regressor
from sklearn import tree
  
# create a regressor object
dt = tree.DecisionTreeRegressor() 
  
dt.fit(X_train_scaled,y_train)

#Making predictions on the Test Set
y_pred_dt = dt.predict(X_test_scaled)
y_pred_dt

#Evaluating the model
print("RMSE of Decision Tree Regression Model is: ",root_mean_squared_error(y_test, y_pred_dt))

#Cross validation of the model
RMSEs = cross_val_score(dt, X_scaled, y, scoring='neg_root_mean_squared_error', cv=10)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

from sklearn.model_selection import RepeatedKFold
cv_strategy=RepeatedKFold(
    n_splits=5, n_repeats=8, random_state=0
)
RMSEs = cross_val_score(lr, X_scaled, y, scoring='neg_root_mean_squared_error', cv=cv_strategy)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

residuals_dt = dt.predict(X_scaled) - y
residuals_dt.head()

sns.histplot(x=residuals_dt, kde=True, stat='proportion');

residuals_dt.mean(), residuals_dt.median(), residuals_dt.std()

g = sns.jointplot(x=y, y=dt.predict(X_scaled), alpha=0.5)
x0, x1 = g.ax_joint.get_xlim()
y0, y1 = g.ax_joint.get_ylim()
lims = [min(x0, y0), max(x1, y1)]
lims = [0, max(x1, y1)]
g.ax_joint.set(xlim=lims, ylim=lims)
g.ax_joint.plot(lims, lims, ':k', alpha=0.3, lw=1);
g.ax_joint.set(xlabel='True Target Value')
g.ax_joint.set(ylabel='Predicted Target Value');

"""###Ridge Regression"""

# import the Ridge regressor
from sklearn.linear_model import Ridge
  
# create a regressor object
ridge = Ridge()
  
ridge.fit(X_train_scaled,y_train)

#Making predictions on the Test Set
y_pred_ridge = ridge.predict(X_test_scaled)
y_pred_ridge

#Evaluating the model
print("RMSE of Ridge Regressor Model is: ",root_mean_squared_error(y_test, y_pred_ridge))

#Cross validation of the model
RMSEs = cross_val_score(ridge, X_scaled, y, scoring='neg_root_mean_squared_error', cv=10)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

from sklearn.model_selection import RepeatedKFold
cv_strategy=RepeatedKFold(
    n_splits=5, n_repeats=8, random_state=0
)
RMSEs = cross_val_score(ridge, X_scaled, y, scoring='neg_root_mean_squared_error', cv=cv_strategy)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

residuals_ridge = ridge.predict(X_scaled) - y
residuals_ridge.head()

sns.histplot(x=residuals_ridge, kde=True, stat='proportion');

residuals_ridge.mean(), residuals_ridge.median(), residuals_ridge.std()

g = sns.jointplot(x=y, y=ridge.predict(X_scaled), alpha=0.5)
x0, x1 = g.ax_joint.get_xlim()
y0, y1 = g.ax_joint.get_ylim()
lims = [min(x0, y0), max(x1, y1)] 
lims = [0, max(x1, y1)]
g.ax_joint.set(xlim=lims, ylim=lims)
g.ax_joint.plot(lims, lims, ':k', alpha=0.3, lw=1);
g.ax_joint.set(xlabel='True Target Value')
g.ax_joint.set(ylabel='Predicted Target Value');

"""###Lasso Regression"""

# import the Lasso regressor
from sklearn.linear_model import Lasso
  
# create a regressor object
lasso = Lasso()
  
lasso.fit(X_train_scaled,y_train)

#Making predictions on the Test Set
y_pred_lasso = lasso.predict(X_test_scaled)
y_pred_lasso

#Evaluating the model
print("RMSE of Lasso Regression Model is: ",root_mean_squared_error(y_test, y_pred_lasso))

#Cross validation of the model
RMSEs = cross_val_score(lasso, X_scaled, y, scoring='neg_root_mean_squared_error', cv=10)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

from sklearn.model_selection import RepeatedKFold
cv_strategy=RepeatedKFold(
    n_splits=5, n_repeats=8, random_state=0
)
RMSEs = cross_val_score(ridge, X_scaled, y, scoring='neg_root_mean_squared_error', cv=cv_strategy)*-1
print(RMSEs)
print(RMSEs.mean(), RMSEs.std())

residuals_lasso = lasso.predict(X_scaled) - y
residuals_lasso.head()

sns.histplot(x=residuals_lasso, kde=True, stat='proportion');

residuals_lasso.mean(), residuals_lasso.median(), residuals_lasso.std()

g = sns.jointplot(x=y, y=lasso.predict(X_scaled), alpha=0.5)
x0, x1 = g.ax_joint.get_xlim()
y0, y1 = g.ax_joint.get_ylim()
lims = [min(x0, y0), max(x1, y1)] # more generic solution
lims = [0, max(x1, y1)]
g.ax_joint.set(xlim=lims, ylim=lims)
g.ax_joint.plot(lims, lims, ':k', alpha=0.3, lw=1);
g.ax_joint.set(xlabel='True Target Value')
g.ax_joint.set(ylabel='Predicted Target Value');

"""###Findings from the outputs
For the regression part of this project, I have built and trained 5 regression models namely Multi Linear, Decision Tree, Ridge and Lasso regression. The RMSE values of these models show us that the Decision Tree Regressor had the highest RMSE value of the trained values whereas the Lasso had the lowest with a value of about 605. This means that the predictions made by this model are off by 605 of the actual value. We are also getting good average Cross-Validation scores which further justifies the fact that for this dataset among the trained regression models the Lasso is the most accurate but there is more work to be done in the future as the residuals and plots against the true and predicted values gives us some interesting results which will be discussed further in this report.

##Data Loading for the Classification Part
For the feature selection part, I will again go with the same features which I have chosen for the Regression part only this time our target variable is price_band which has values of low, medium, high and very high which means that the Classification Algorithms will solve a multiclass classification problem.
"""

clf_df = pd.read_csv(Path+'/Adverts_Classification.csv')
clf_df.head()

# The final dataset to be used for the Classification Algorithms
clf_df = clf_df.drop(columns=['public_reference','reg_code','vehicle_condition','crossover_car_and_van',
                              'standard_make','standard_model','standard_colour','year_of_registration'])
clf_df.head()

"""###Target Class Exploration"""

clf_df['price_band'].value_counts()

"""###Data Preparation for the Classification Models"""

# Handling the Outliers
Q1 = clf_df.quantile(0.25)
Q3 = clf_df.quantile(0.75)
IQR = Q3 - Q1

clf_df = clf_df[~((clf_df < (Q1 - 1.5 * IQR)) |(clf_df > (Q3 + 1.5 * IQR))).any(axis=1)]
clf_df.shape

# Handling the missing values
clf_df.isnull().sum()

clf_df['mileage'] = clf_df['mileage'].fillna(clf_df['mileage'].median())
clf_df.isnull().sum()

# Seperating the feature variables (X) from the target variable (y)
X = clf_df.drop(columns=['price_band'],axis=1)
y = clf_df.price_band
X.head()

y

# Getting the dummy values of the categorical features and dropping the last column of each
X = pd.get_dummies(data=X,drop_first=True)
X.head()

# Splitting the data into training and test sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42,
    # `stratify` preserves the class distribution in each partition (train/test)
    stratify=y
)
X_train.shape, y_train.shape, X_test.shape, y_test.shape

"""Given the size of the dataset and running a number of iterations in the rough work of the project, I came to understand that models such as KNN and SVM are extremely slow in execution due to their nature thus making them computationally expensive to run. For  this project in the Classification part, I have decided to use only 50% data for the training set and I have also used a dummy classifier on this dataset just to get a baseline accuracy score to compare it with other models. I have also decided to include the same number of features as I did with the regression tasks to ensure that the KNN and SVM models can run faster. I have noticed that for Logistic Regression (LR) and Decision Tree (DT) this reduction of training samples does not make much of a difference for the predicted outputs so it can be assumed that we will see similar cases for K-Nearest Neighbours (KNN) and Support Vector Machine (SVM) algorithms which I will build and train in the following parts. From the distribution of the target classes, we can see that we have imbalanced class distribution as vehicles with low prices are the least as price bands with high is the most present in the dataset. To retain the class distribution in the test and train set I have stratified the target variable (y). After building and running the models on the training set to test them on the testing set I have used accuracy score which calculates the subset accuracy (micro accuracy) and balanced accuracy function which calculates which works best to deal with imbalanced datasets as it calculates the average recall found by the models on each of the classes (macro accuracy). I have also drawn the confusion matrix of the results on the test set to get some insights into the prediction of the model performances.

#Building, Training and Evaluation of Classification Models

###Dummy Classifier
"""

# Dummy Classifier
from sklearn.dummy import DummyClassifier
dummyc = DummyClassifier()
dummyc.fit(X_train, y_train)

dummyc_acc_train = accuracy_score(y_train, dummyc.predict(X_train))
dummyc_bacc_train = balanced_accuracy_score(y_train, dummyc.predict(X_train))
dummyc_acc_test = accuracy_score(y_test, dummyc.predict(X_test))
dummyc_bacc_test = balanced_accuracy_score(y_test, dummyc.predict(X_test))

dummyc_scores_df = pd.DataFrame(
    dict(
        micro_acc_train=dummyc_acc_train,
        macro_acc_train=dummyc_bacc_train,
        micro_acc_test=dummyc_acc_test,
        macro_acc_test=dummyc_bacc_test
    ), 
    index=['Dummy']
)
dummyc_scores_df

cm = confusion_matrix(
    y_test, dummyc.predict(X_test), normalize='true'
)
ConfusionMatrixDisplay(confusion_matrix=cm).plot();

"""###Decision Tree (DT)"""

from sklearn.tree import DecisionTreeClassifier

# max_depth=2
dtc_md2 = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)
dtc_md2_acc_train = accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md2_bacc_train = balanced_accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md2_acc_test = accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md2_bacc_test = balanced_accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md2_acc_train = accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md2_bacc_train = balanced_accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md2_acc_test = accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md2_bacc_test = balanced_accuracy_score(y_test, dtc_md2.predict(X_test))

# DT With Maxdepth 5
dtc_md5 = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)
dtc_md5_acc_train = accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md5_bacc_train = balanced_accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md5_acc_test = accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md5_bacc_test = balanced_accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md5_acc_train = accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md5_bacc_train = balanced_accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md5_acc_test = accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md5_bacc_test = balanced_accuracy_score(y_test, dtc_md2.predict(X_test))

# DT With Maxdepth 7
dtc_md7 = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)
dtc_md7_acc_train = accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md7_bacc_train = balanced_accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md7_acc_test = accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md7_bacc_test = balanced_accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md7_acc_train = accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md7_bacc_train = balanced_accuracy_score(y_train, dtc_md2.predict(X_train))
dtc_md7_acc_test = accuracy_score(y_test, dtc_md2.predict(X_test))
dtc_md7_bacc_test = balanced_accuracy_score(y_test, dtc_md2.predict(X_test))

dtc_scores_df = pd.DataFrame(
    dict(
        micro_acc_train=[dtc_md2_acc_train, dtc_md5_acc_train, dtc_md7_acc_train],
        macro_acc_train=[dtc_md2_bacc_train, dtc_md5_bacc_train, dtc_md7_bacc_train],
        micro_acc_test=[dtc_md2_acc_test, dtc_md5_acc_test, dtc_md7_acc_test],
        macro_acc_test=[dtc_md2_bacc_test, dtc_md5_bacc_test, dtc_md7_bacc_test]
    ), 
    index=['DecisionTree_MaxDepth_2', 'DecisionTree_MaxDepth_5', 'DecisionTree_MaxDepth_7']
)
dtc_scores_df.sort_values('macro_acc_test', ascending=False)

# With max depths 2,5 and 7 we get the same results
cm = confusion_matrix(
    y_test, dtc_md2.predict(X_test), normalize=None
)
ConfusionMatrixDisplay(confusion_matrix=cm).plot();

from sklearn.linear_model import LogisticRegression

lgr = LogisticRegression(solver='saga',n_jobs=-1)
lgr = Pipeline([('scaler', StandardScaler()), ('model', lgr)])
lgr.fit(X_train, y_train)
lgr_acc_train = accuracy_score(y_train, lgr.predict(X_train))
lgr_bacc_train = balanced_accuracy_score(y_train, lgr.predict(X_train))
lgr_acc_test = accuracy_score(y_test, lgr.predict(X_test))
lgr_bacc_test = balanced_accuracy_score(y_test, lgr.predict(X_test))

lgr_scores_df = pd.DataFrame(
    dict(
        micro_acc_train=lgr_acc_train,
        macro_acc_train=lgr_bacc_train,
        micro_acc_test=lgr_acc_test,
        macro_acc_test=lgr_bacc_test
    ), 
    index=['LGR']
)
lgr_scores_df

cm = confusion_matrix(
    y_test, lgr.predict(X_test), normalize=None
)
ConfusionMatrixDisplay(confusion_matrix=cm).plot();

"""###K-Nearest Neighbours (KNN)"""

from sklearn.neighbors import KNeighborsClassifier
MinMaxScaler().fit_transform(X_train)

# fit/evaluate: kNN 5 distance
knnc_5d = KNeighborsClassifier(5, weights='distance', n_jobs=-1)
knnc_5d = Pipeline([('scaler', StandardScaler()), ('model', knnc_5d)])
knnc_5d.fit(X_train, y_train)
knnc_5d_acc_train = accuracy_score(y_train, knnc_5d.predict(X_train))
knnc_5d_bacc_train = balanced_accuracy_score(y_train, knnc_5d.predict(X_train))
knnc_5d_acc_test = accuracy_score(y_test, knnc_5d.predict(X_test))
knnc_5d_bacc_test = balanced_accuracy_score(y_test, knnc_5d.predict(X_test))

knnc_scores_df = pd.DataFrame(
    dict(
        micro_acc_train=[knnc_5d_acc_train],
        macro_acc_train=[knnc_5d_bacc_train],
        micro_acc_test=[knnc_5d_acc_test],
        macro_acc_test=[knnc_5d_bacc_test]
    ), 
    index=['kNN with K = 5 and Weight = Distance']
)
knnc_scores_df.sort_values('macro_acc_test', ascending=False)

cm = confusion_matrix(
    y_test, knnc_5d.predict(X_test), normalize=None
)
ConfusionMatrixDisplay(confusion_matrix=cm).plot();

"""###Support Vector Machine (SVM)"""

from sklearn.svm import SVC

svc = SVC(kernel='rbf',C=1)
svc = Pipeline([('scaler', StandardScaler()), ('model', svc)])
svc.fit(X_train, y_train)
svc_acc_train = accuracy_score(y_train, svc.predict(X_train))
svc_bacc_train = balanced_accuracy_score(y_train, svc.predict(X_train))
svc_acc_test = accuracy_score(y_test, svc.predict(X_test))
svc_bacc_test = balanced_accuracy_score(y_test, svc.predict(X_test))

svc_scores_df = pd.DataFrame(
    dict(
        micro_acc_train=svc_acc_train,
        macro_acc_train=svc_bacc_train,
        micro_acc_test=svc_acc_test,
        macro_acc_test=svc_bacc_test
    ), 
    index=['SVM with kernel = rbf and C = 1']
)
svc_scores_df

cm = confusion_matrix(
    y_test, svc.predict(X_test), normalize=None
)
ConfusionMatrixDisplay(confusion_matrix=cm).plot();

# Showing all the accuracy scores together
scores_df = pd.concat(
    [
        dummyc_scores_df, knnc_scores_df, dtc_scores_df, svc_scores_df, lgr_scores_df
    ],
    axis='rows'
)
scores_df.sort_values('macro_acc_test', ascending=False)

"""### Findings from the Outputs
From the results obtained from the outputs I would select KNN to be the best predictor for this project compared to all the other classifiers this is because we are getting excellent micro and macro accuracy scores on the training sets but lower scores but not too bad on the test sets. Whereas LRs micro accuracy on the test set is higher than it's training set and the same is seen in SVMs case and this shows that KNN is not overfitting and SVM and LR has missinterpreted the data during training. In contrast, the DT has the lowest accuracy scores. However, there is a saying in Machine Learning terms that there no best model and this further resembles when we investigate the Confusion Matrix of the KNN where we can see that the total number of misclassification of the model is 7000+ whereas for SVM and LR this figure is 6000+ out of the 46320 predictions made (value found by calculating the total numbers in the confusion matrix).

#Conclusion
From the trained models for regression, I found the Lasso model to be the most accurate which is expected as these models solve a regularisation problem which the Linear Regression and Decision Tree models do not. Also, Multilinear Regression Models work best on linearly separable data or smaller datasets.

https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net

Although the results of the Cross Validation average RMSE of the Lasso model is quite small, when we look at the plot of true target value and predicted target values of Lasso we see that there is not much difference between them and the mean of the residuals is about 2 which means that there is a considerable amount of overfitting as the mean of a regression model should , in theory, be zero.

https://www.statisticshowto.com/residual/

From the classification task, I found KNN to be the best predictor among LR, DT and SVM. This is because the MinMaxSclaer is applied on the training set and then the StandardScaler which helps KNN models to learn the data better. We can also see from the Confusion Matrix that it predicts the minority class (low price band) a bit better too. However, this does not mean that KNN is the ultimate solution as discussed earlier if we look at the Confusion Matrix of the results given by KNN closely, we can see that it is misclassifying the higher number of data compared to other models. Also, the SVM and KNN are slow when run on a large dataset and all the classification models require significant parameter tuning.

https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222

https://medium.com/@dannymvarghese/comparative-study-on-classic-machine-learning-algorithms-part-2-5ab58b683ec0

###Future Recommendations
Given the problems found after the assessment of the performances of the models run there is plenty of room for improvement but due to the time constraints some tasks were not carried out which I would like to add as future work.

Firstly,  some feature engineering could be done on the reg_code column which I had dropped for this task. To identify the most important features the feature importance technique could be applied. As we saw that most of the models require a significant amount of hyperparameter tuning of the Classification models are needed to get the optimal output and to find the right parameters we can implement a GridSearch Algorithm. Lastly, given the size of this data, we saw that models such as SVM and KNN are very slow in fitting and making predictions and we also observed some accurate results which mean that we should try to fit and train other models for both Regression and Classification tasks such as Ensemble Models for a better comparison of the trained models and also use 20% data as the test set which is the standard percentage used for Machine Learning projects.

https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html

https://machinelearningmastery.com/why-use-ensemble-learning/
"""